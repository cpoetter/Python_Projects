{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from dipy.viz import fvtk\n",
    "import scipy.stats as average\n",
    "import dipy.core.sphere as sphere\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import scipy.io\n",
    "from dipy.tracking import utils\n",
    "from dipy.tracking.local import LocalTracking\n",
    "from dipy.tracking.eudx import EuDX\n",
    "import vtk  \n",
    "from dipy.core.gradients import gradient_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_hcp_data(path, subject):\n",
    "    '''Load data, affine and gradients from the HCP data set'''\n",
    "    \n",
    "    dirname_praefix = '/T1w/Diffusion/'\n",
    "    dirname = path + subject + dirname_praefix\n",
    "    \n",
    "    nii_filename = dirname + 'data.nii.gz'\n",
    "    bval_filename = dirname + 'bvals'\n",
    "    bvec_filename = dirname + 'bvecs'\n",
    "\n",
    "    print \"Loading data\"\n",
    "    img = nib.load(nii_filename)\n",
    "    bvals = np.loadtxt(bval_filename)\n",
    "    bvecs = np.loadtxt(bvec_filename).T\n",
    "    \n",
    "    print \"Correcting data\"\n",
    "    shell_mask = np.round(bvals/100.0, 0)*100\n",
    "    bvals[bvals < 0.01*np.max(bvals)] = 0 # set bval of b0 meassurements to 0\n",
    "    \n",
    "    print \"Creating shells for LiFE\"\n",
    "    mask_for_life = np.logical_or(bvals > 0.98*np.max(bvals), bvals == 0.0)\n",
    "    bvals = bvals[mask_for_life]\n",
    "    bvecs = bvecs[mask_for_life]\n",
    "    \n",
    "    print \"Retrieving data, affine and gradients\"\n",
    "    data = img.get_data()\n",
    "    affine = img.get_affine()\n",
    "    header = img.get_header()\n",
    "    gtab = gradient_table(bvals,bvecs)\n",
    "    \n",
    "    print \"Masking data for LiFE\"\n",
    "    data = data[..., mask_for_life]\n",
    "    header['dim'][4] = data.shape[-1]\n",
    "    \n",
    "    return data, affine, gtab, header, shell_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_trk(streamlines, header, filename):\n",
    "    '''Save tractography to a .trk file'''\n",
    "    \n",
    "    print \"Save tracks in %s\" % filename\n",
    "    hdr = nib.trackvis.empty_header()\n",
    "    hdr['voxel_size'] =  header.get_zooms()[:3]\n",
    "    hdr['voxel_order'] = 'LAS' #'RAS'\n",
    "    hdr['dim'] = header['dim'][1:4]\n",
    "    \n",
    "    ## Move streamlines to \"trackvis space\"\n",
    "    #trackvis_point_space = utils.affine_for_trackvis(voxel_size)\n",
    "    #lr_sf_trk = utils.move_streamlines(streamlines, trackvis_point_space, input_space=np.eye(4))\n",
    "    #lr_sf_trk = list(lr_sf_trk)\n",
    "    \n",
    "    strm = ((sl, None, None) for sl in streamlines)\n",
    "    nib.trackvis.write(filename, strm, hdr, points_space='voxel')\n",
    "    \n",
    "def fiber_tracking(peaks, mask):\n",
    "    print \"Start Fibertracking\"\n",
    "    seeds = utils.seeds_from_mask(mask, density=[2, 2, 2])\n",
    "    streamline_generator = EuDX(peaks.peak_values, peaks.peak_indices, odf_vertices=peaks.sphere.vertices, a_low=.05, step_sz=.5, seeds=seeds)\n",
    "    streamlines = list(streamline_generator)\n",
    "    return streamlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vtk_show(renderer, w=750, h=750):\n",
    "    \"\"\"\n",
    "    Takes vtkRenderer instance and returns an IPython Image with the rendering.\n",
    "    \"\"\"\n",
    "    renderWindow = vtk.vtkRenderWindow()\n",
    "    renderWindow.SetOffScreenRendering(1)\n",
    "    renderWindow.AddRenderer(renderer)\n",
    "    renderWindow.SetSize(w, h)\n",
    "    renderWindow.Render()\n",
    "     \n",
    "    windowToImageFilter = vtk.vtkWindowToImageFilter()\n",
    "    windowToImageFilter.SetInput(renderWindow)\n",
    "    windowToImageFilter.Update()\n",
    "     \n",
    "    writer = vtk.vtkPNGWriter()\n",
    "    writer.SetWriteToMemory(1)\n",
    "    writer.SetInputConnection(windowToImageFilter.GetOutputPort())\n",
    "    writer.Write()\n",
    "    data = str(buffer(writer.GetResult()))\n",
    "    \n",
    "    from IPython.display import Image\n",
    "    return Image(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_as_matlab_file(path, **kwargs):\n",
    "    # Saves single numpy variable as matlab file\n",
    "    # Exp.: a = np.array([1, 2, 3]) \n",
    "    # save_as_matlab_file('file_name', variable_name = a)\n",
    "    print 'Save %s' %path\n",
    "    scipy.io.savemat(path, mdict=kwargs)\n",
    "    return True\n",
    "    \n",
    "def load_matlab_file(path):\n",
    "    # Loads variable stored in matlab file and returns it as numpy array\n",
    "    #variable_dict = scipy.io.loadmat(path)\n",
    "    #variable_names = [x for x in variable_dict.keys() if \"__\" not in x]\n",
    "    #content = [variable_dict[x] for x in variable_names]\n",
    "    variable_dict = scipy.io.loadmat(path)\n",
    "    variable_names = [x for x in variable_dict.keys() if \"__\" in x]\n",
    "    for i in variable_names:\n",
    "        del variable_dict[i]\n",
    "    return variable_dict\n",
    "\n",
    "def save_as_nifti(path, data, affine):\n",
    "    # Saves data as a nifti file\n",
    "    print 'Save %s' %path\n",
    "    image = nib.Nifti1Image(data, affine)\n",
    "    filename = path + '.nii.gz'\n",
    "    nib.save(image, filename)\n",
    "    return True\n",
    "\n",
    "def load_nifti(path):\n",
    "    # Loads a nifti file and returns the data\n",
    "    filename = path  + '.nii.gz'\n",
    "    image = nib.load(filename)\n",
    "    return image.get_data()\n",
    "\n",
    "# Loading nifti image, data, affine and gtabs\n",
    "def load_nifti_image(path, nifti_name, bvals_name, bvecs_name):\n",
    "    nifti_path = path + nifti_name\n",
    "    bvals_path = path + bvals_name\n",
    "    bvecs_path = path + bvecs_name\n",
    "\n",
    "    img = nib.load(nifti_path)\n",
    "    data = img.get_data()\n",
    "    affine = img.affine\n",
    "    header = img.header\n",
    "    \n",
    "    bvals, bvecs = read_bvals_bvecs(bvals_path, bvecs_path)\n",
    "    gtab = gradient_table(bvals, bvecs)\n",
    "    \n",
    "    print 'Image %s loaded' % nifti_name\n",
    "    return img, data, affine, header, gtab\n",
    "\n",
    "def save_bvecs(bvecs, path, name):\n",
    "    with open(path + name, 'w') as fp:\n",
    "        fp.write(' '.join(['%0.4f' % bv for bv in np.squeeze(np.asarray(bvecs[:, 0]))]) + '\\n')\n",
    "        fp.write(' '.join(['%0.4f' % bv for bv in np.squeeze(np.asarray(bvecs[:, 1]))]) + '\\n')\n",
    "        fp.write(' '.join(['%0.4f' % bv for bv in np.squeeze(np.asarray(bvecs[:, 2]))]) + '\\n')\n",
    "    print 'bvecs %s successfully saved' % name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculates the Correlation Coefficient\n",
    "# Faster then the build in functions for correlation\n",
    "def CC(data1, data2, predicted_data1, predicted_data2, white_matter):\n",
    "    predicted_data1_masked_demean = predicted_data1_masked - np.mean(predicted_data1_masked, -1)[..., np.newaxis]\n",
    "    predicted_data2_masked_demean = predicted_data2_masked - np.mean(predicted_data2_masked, -1)[..., np.newaxis]\n",
    "    data1_masked_demean = data1_masked - np.mean(data1_masked, -1)[..., np.newaxis]\n",
    "    data2_masked_demean = data2_masked - np.mean(data2_masked, -1)[..., np.newaxis]\n",
    "\n",
    "    predicted_data1_masked_demean_xx = np.sum(predicted_data1_masked_demean ** 2, -1)\n",
    "    predicted_data2_masked_demean_xx = np.sum(predicted_data2_masked_demean ** 2, -1)\n",
    "    data1_masked_demean_xx = np.sum(data1_masked_demean ** 2, -1)\n",
    "    data2_masked_demean_xx = np.sum(data2_masked_demean ** 2, -1)\n",
    "\n",
    "    CC_M1_D2_masked = np.sum(predicted_data1_masked_demean * data2_masked_demean, -1)*1.0/np.sqrt(predicted_data1_masked_demean_xx * data2_masked_demean_xx)\n",
    "    CC_M2_D1_masked = np.sum(predicted_data2_masked_demean * data1_masked_demean, -1)*1.0/np.sqrt(predicted_data2_masked_demean_xx * data1_masked_demean_xx)\n",
    "    CC_D1_D2_masked = np.sum(data1_masked_demean * data2_masked_demean, -1)*1.0/np.sqrt(data1_masked_demean_xx * data2_masked_demean_xx)\n",
    "\n",
    "    # Unmasking Data\n",
    "    CC_M1_D2 = np.zeros(data1.shape[:-1])\n",
    "    CC_M2_D1 = np.zeros(data1.shape[:-1])\n",
    "    CC_D1_D2 = np.zeros(data1.shape[:-1])\n",
    "\n",
    "    CC_M1_D2[white_matter] = CC_M1_D2_masked\n",
    "    CC_M2_D1[white_matter] = CC_M2_D1_masked\n",
    "    CC_D1_D2[white_matter] = CC_D1_D2_masked\n",
    "    \n",
    "    return CC_M1_D2, CC_M2_D1, CC_D1_D2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculates rRMSE between two data sets\n",
    "def rRMSE(data1, data2, predicted_data1, predicted_data2, white_matter):\n",
    "    data1_masked = data1[white_matter]\n",
    "    data2_masked = data2[white_matter]\n",
    "    predicted_data1_masked = predicted_data1[white_matter]\n",
    "    predicted_data2_masked = predicted_data2[white_matter]\n",
    "\n",
    "    #Calculation rRMSE\n",
    "    RMSE_M1_D2_masked = np.sqrt(np.average((predicted_data1_masked-data2_masked)**2, axis=-1, weights=data2_masked.astype(bool)))\n",
    "    RMSE_M2_D1_masked = np.sqrt(np.average((predicted_data2_masked-data1_masked)**2, axis=-1, weights=data1_masked.astype(bool)))\n",
    "    RMSE_D1_D2_masked = np.sqrt(np.average((data1_masked-data2_masked)**2, axis=-1, weights=data1_masked.astype(bool)))\n",
    "\n",
    "    all_zero = (RMSE_D1_D2_masked == 0).astype(int)\n",
    "    rRMSE_masked = (RMSE_M1_D2_masked + RMSE_M2_D1_masked)/(2 * RMSE_D1_D2_masked + all_zero)\n",
    "\n",
    "    # Unmasking Data\n",
    "    rRMSE = np.zeros(data1.shape[:-1])\n",
    "    rRMSE[white_matter] = rRMSE_masked\n",
    "        \n",
    "    return rRMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw_histogramm(rRMSE_masked):\n",
    "    bins_rRMSE = np.linspace(0.6,1.1,100)\n",
    "    hist_rRMSE = np.histogram(rRMSE_masked, bins=bins_rRMSE)\n",
    "    plt.plot(bins_rRMSE[:-1], hist_rRMSE[0], 'r')\n",
    "    plt.xlim(xmin=0.6)\n",
    "    plt.xlim(xmax=1.1)\n",
    "    plt.ylim(ymax=max(hist_rRMSE[0])+100)\n",
    "    plt.xlabel('rRMSE')\n",
    "    plt.ylabel('Quantity')\n",
    "    plt.show()\n",
    "\n",
    "    print 'Most Appearing rRMSE:        ', bins_rRMSE[:-1][np.argmax(hist_rRMSE[0])]\n",
    "    print 'Mean:                        ', np.mean(bins_rRMSE[:-1])\n",
    "    print 'Total rRMSE Sum:             ', np.sum(hist_rRMSE[0]*bins_rRMSE[:-1])\n",
    "    \n",
    "    for i in range(hist_rRMSE[0].shape[0]):\n",
    "        print '(', \"{0:.3f}\".format(bins_rRMSE[i]), ',', hist_rRMSE[0][i], ')'   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_histogramm(rRMSE_masked, rRMSE_masked2):\n",
    "    bins_rRMSE = np.linspace(0.6,1.1,100)\n",
    "    hist_rRMSE = np.histogram(rRMSE_masked, bins=bins_rRMSE)\n",
    "    hist_rRMSE2 = np.histogram(rRMSE_masked2, bins=bins_rRMSE)\n",
    "    red = plt.plot(bins_rRMSE[:-1], hist_rRMSE[0], 'r')\n",
    "    blue = plt.plot(bins_rRMSE[:-1], hist_rRMSE2[0], 'b')\n",
    "    plt.xlim(xmin=0.6)\n",
    "    plt.xlim(xmax=1.1)\n",
    "    plt.ylim(ymax=max(hist_rRMSE[0])+100)\n",
    "    plt.xlabel('rRMSE')\n",
    "    plt.ylabel('Quantity')\n",
    "    plt.legend((red[0], blue[0]), ('Dataset 1', 'Dataset 2') )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw_p(p, x):\n",
    "    ren = fvtk.ren()\n",
    "    raw_data = x * np.array([p, p, p])\n",
    "    #point = fvtk.point(raw_data, fvtk.colors.red, point_radius=0.00001)\n",
    "    #fvtk.add(ren, point)\n",
    "    #fvtk.show(ren)\n",
    "    \n",
    "    new_sphere = sphere.Sphere(xyz=x)\n",
    "    sf1 = fvtk.sphere_funcs(raw_data, new_sphere, colormap=None, norm=False, scale=0)\n",
    "    sf1.GetProperty().SetOpacity(0.35)\n",
    "    fvtk.add(ren, sf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def draw_odf(data, gtab, odf, sphere_odf):\n",
    "\n",
    "    ren = fvtk.ren()\n",
    "    bvecs = gtab.bvecs\n",
    "    raw_data = bvecs * np.array([data, data, data]).T\n",
    "\n",
    "    # Draw Raw Data as points, Red means outliers    \n",
    "    point = fvtk.point(raw_data[~gtab.b0s_mask, :], fvtk.colors.red, point_radius=0.05)\n",
    "    fvtk.add(ren, point)\n",
    "\n",
    "    sf1 = fvtk.sphere_funcs(odf, sphere_odf, colormap=None, norm=False, scale=0)\n",
    "    sf1.GetProperty().SetOpacity(0.35)\n",
    "    fvtk.add(ren, sf1)\n",
    "    \n",
    "    fvtk.show(ren)\n",
    "\n",
    "def draw_points(data, gtab, predicted_data):\n",
    "    ren = fvtk.ren()\n",
    "    bvecs = gtab.bvecs\n",
    "    raw_points = bvecs * np.array([data, data, data]).T\n",
    "    predicted_points = bvecs * np.array([predicted_data, predicted_data, predicted_data]).T\n",
    "\n",
    "    # Draw Raw Data as points, Red means outliers    \n",
    "    point = fvtk.point(raw_points[~gtab.b0s_mask, :], fvtk.colors.red, point_radius=0.02)\n",
    "    fvtk.add(ren, point)\n",
    "\n",
    "    new_sphere = sphere.Sphere(xyz=bvecs[~gtab.b0s_mask, :])\n",
    "    sf1 = fvtk.sphere_funcs(predicted_data[~gtab.b0s_mask], new_sphere, colormap=None, norm=False, scale=0)\n",
    "    sf1.GetProperty().SetOpacity(0.35)\n",
    "    fvtk.add(ren, sf1)\n",
    "    \n",
    "    fvtk.show(ren)\n",
    "\n",
    "def draw_ellipsoid(data, gtab, outliers, data_without_noise):\n",
    "    \n",
    "    bvecs = gtab.bvecs\n",
    "    raw_data = bvecs * np.array([data, data, data]).T\n",
    "    \n",
    "    ren = fvtk.ren()\n",
    "    \n",
    "    # Draw Sphere of predicted data\n",
    "    new_sphere = sphere.Sphere(xyz=bvecs[~gtab.b0s_mask, :])\n",
    "    sf1 = fvtk.sphere_funcs(data_without_noise[~gtab.b0s_mask], new_sphere, colormap=None, norm=False, scale=1)\n",
    "    sf1.GetProperty().SetOpacity(0.35)\n",
    "    fvtk.add(ren, sf1)\n",
    "    \n",
    "    # Draw Raw Data as points, Red means outliers\n",
    "    good_values = [index for index, voxel in enumerate(outliers) if voxel == 0]\n",
    "    bad_values = [index for index, voxel in enumerate(outliers) if voxel == 1]\n",
    "    point_actor_good = fvtk.point(raw_data[good_values, :], fvtk.colors.yellow, point_radius=.05)\n",
    "    point_actor_bad = fvtk.point(raw_data[bad_values, :], fvtk.colors.red, point_radius=0.05)\n",
    "    fvtk.add(ren, point_actor_good)\n",
    "    fvtk.add(ren, point_actor_bad)\n",
    "\n",
    "    fvtk.show(ren)\n",
    "    \n",
    "def draw_adc(D_noisy, D, threeD = False):\n",
    "    \n",
    "    # 3D Plot\n",
    "    if threeD == True:\n",
    "        \n",
    "        amound = 50\n",
    "        alpha = np.linspace(0, 2*np.pi, amound)\n",
    "        theta = np.linspace(0, 2*np.pi, amound)\n",
    "        vector = np.empty((amound**2, 3))\n",
    "        vector[:, 0] = (np.outer(np.sin(theta), np.cos(alpha))).reshape((-1,1))[:,0]\n",
    "        vector[:, 1] = (np.outer(np.sin(theta), np.sin(alpha))).reshape((-1,1))[:,0]\n",
    "        vector[:, 2] = (np.outer(np.cos(theta), np.ones(amound))).reshape((-1,1))[:,0]\n",
    "    \n",
    "        adc_noisy = np.empty((vector.shape[0],3))\n",
    "        shape_noisy = np.empty((vector.shape[0],1))\n",
    "        shape = np.empty((vector.shape[0],1))\n",
    "\n",
    "        for i in range(vector.shape[0]):\n",
    "            adc_noisy[i] = np.dot(vector[i], np.dot(vector[i], np.dot(D_noisy, vector[i].T)))\n",
    "            shape_noisy[i] = np.dot(vector[i], np.dot(D_noisy, vector[i].T))\n",
    "            shape[i] = np.dot(vector[i], np.dot(D, vector[i].T))\n",
    "\n",
    "        ren = fvtk.ren() \n",
    "\n",
    "        # noisy sphere\n",
    "        new_sphere = sphere.Sphere(xyz=vector)\n",
    "        sf1 = fvtk.sphere_funcs(shape_noisy[:, 0], new_sphere, colormap=None, norm=False, scale=0.0001)\n",
    "        sf1.GetProperty().SetOpacity(0.35)\n",
    "        sf1.GetProperty().SetColor((1, 0, 0))\n",
    "        fvtk.add(ren, sf1)\n",
    "\n",
    "        # ideal sphere\n",
    "        sf2 = fvtk.sphere_funcs(shape[:, 0], new_sphere, colormap=None, norm=False, scale=0.0001)\n",
    "        sf2.GetProperty().SetOpacity(0.35)\n",
    "        fvtk.add(ren, sf2)\n",
    "        #point_actor_bad = fvtk.point(adc_noisy, fvtk.colors.red, point_radius=0.00003)\n",
    "        #fvtk.add(ren, point_actor_bad)\n",
    "\n",
    "        fvtk.show(ren)\n",
    "        \n",
    "    # 2D Plot in XY-Plane\n",
    "    alpha = np.linspace(0, 2*np.pi, 100)\n",
    "    vector = np.empty((100, 3))\n",
    "    vector[:, 0] = np.cos(alpha)\n",
    "    vector[:, 1] = np.sin(alpha)\n",
    "    vector[:, 2] = 0.0\n",
    "    adc_noisy_2d = np.empty((vector.shape[0],3))\n",
    "    adc_2d = np.empty((vector.shape[0],3))\n",
    "    for i in range(vector.shape[0]):\n",
    "        adc_noisy_2d[i] = np.dot(vector[i], np.dot(vector[i], np.dot(D_noisy, vector[i].T)))\n",
    "        adc_2d[i] = np.dot(vector[i], np.dot(vector[i], np.dot(D, vector[i].T)))\n",
    "    \n",
    "    # Change Axis so that there is 20% room on each side of the plot\n",
    "    x = np.concatenate((adc_noisy_2d, adc_2d), axis=0)\n",
    "    minimum = np.min(x, axis=0)    \n",
    "    maximum = np.max(x, axis=0)\n",
    "    plt.plot(adc_noisy_2d[:,0],adc_noisy_2d[:,1], 'r')\n",
    "    plt.plot(adc_2d[:,0],adc_2d[:,1],'b')\n",
    "    plt.axis([minimum[0]*1.2, maximum[0]*1.2, minimum[1]*1.2, maximum[1]*1.2])\n",
    "    plt.xlabel('ADC (mm2*s-1)')\n",
    "    plt.ylabel('ADC (mm2*s-1)')\n",
    "    red_patch = mpatches.Patch(color='red', label='Noisy ADC')\n",
    "    blue_patch = mpatches.Patch(color='blue', label='Ideal ADC')\n",
    "    plt.legend(handles=[red_patch, blue_patch])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def draw_p(p, x, new_sphere):\n",
    "    ren = fvtk.ren()\n",
    "    raw_data = x * np.array([p, p, p])\n",
    "\n",
    "    sf1 = fvtk.sphere_funcs(raw_data, new_sphere, colormap=None, norm=False, scale=0)\n",
    "    sf1.GetProperty().SetOpacity(0.35)\n",
    "    fvtk.add(ren, sf1)\n",
    "    \n",
    "    fvtk.show(ren)\n",
    "    \n",
    "def draw_p_2D(p, x):\n",
    "    raw_data = x * np.array([p, p, p])\n",
    "    plt.plot(raw_data[0, :] ,raw_data[2, :], 'ro', ms=2.0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
